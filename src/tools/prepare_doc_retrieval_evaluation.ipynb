{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "import json\n",
    "import unicodedata\n",
    "\n",
    "foldername = \"wice\"\n",
    "year = \"2023\" if foldername == \"wice\" else \"2017\"\n",
    "\n",
    "\n",
    "BASE_PATH = os.path.join(os.path.abspath(os.curdir), \"..\", \"..\", \"data\")\n",
    "DB_PATH = os.path.join(BASE_PATH, \"db_files\", f\"enwiki-{year}-original-full.db\")\n",
    "OUT_PATH = os.path.join(os.path.abspath(os.curdir), \"..\", \"..\", \"out\")\n",
    "\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "wiki_db = conn.cursor()\n",
    "results = wiki_db.execute(\n",
    "    \"SELECT id FROM documents ORDER BY id COLLATE NOCASE ASC\"\n",
    ").fetchall()\n",
    "title_id_dict = {title[0]: id for id, title in enumerate(results)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LABELED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "DEV_FILE = os.path.join(BASE_PATH, foldername, f\"{foldername}_dev_release_v1.1.json\")\n",
    "count = 0\n",
    "\n",
    "def dict_ids(json_file):\n",
    "    # Create a dictionary to map uid to title using title_id_dict\n",
    "    uid_to_title_dict = {}\n",
    "    global count\n",
    "    for item in json_file:\n",
    "        uid = item['uid']\n",
    "        uid_to_title_dict[uid] = {}\n",
    "        # Retrieve title from title_id_dict using supporting facts or some logic\n",
    "        for fact in item['supporting_facts']:\n",
    "            title = unicodedata.normalize(\"NFD\", fact[0])  # Assuming title is the first element\n",
    "            if title in title_id_dict:\n",
    "                uid_to_title_dict[uid][title_id_dict[title]] = 1\n",
    "            else:\n",
    "                count += 1\n",
    "\n",
    "    return uid_to_title_dict\n",
    "\n",
    "with open(DEV_FILE,\"r\") as json_file:\n",
    "    claim_json = json.load(json_file)\n",
    "\n",
    "original_labeled = dict_ids(claim_json)\n",
    "print(count)\n",
    "with open(f'../../out/doc_retrieval/{foldername}_dev_dict.json', 'w') as json_file:\n",
    "    json.dump(original_labeled, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = set()\n",
    "def dict_ids_results(json_file, id_key='uid'):\n",
    "    uid_to_title_dict = {}\n",
    "    global count\n",
    "    count = set()\n",
    "    for item in json_file:\n",
    "        uid = item[id_key]\n",
    "        uid_to_title_dict[uid] = {}\n",
    "        # Retrieve title from title_id_dict using supporting facts or some logic\n",
    "        [c[0] for c in claim_json[0]['context']]\n",
    "        for fact in item['context']:\n",
    "            title = unicodedata.normalize(\"NFD\", fact[0]) \n",
    "            if title in title_id_dict:\n",
    "                uid_to_title_dict[uid][title_id_dict[title]] = 1\n",
    "            else:\n",
    "                count.add(title)\n",
    "    return uid_to_title_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original 0\n",
      "cite 0\n",
      "claim 0\n",
      "fusion 0\n"
     ]
    }
   ],
   "source": [
    "setting_files = [\"original-full\", \"cite-full\", \"claim-full\", \"fusion-full\"]\n",
    "\n",
    "for setting in setting_files:\n",
    "    DOC_PATH = os.path.join(BASE_PATH, \"hover_files\", foldername, \"bm25\", setting, \"doc_retrieval\", \"hover_dev_doc_retrieval.json\")\n",
    "    with open(DOC_PATH,\"r\") as json_file:\n",
    "        claim_json = json.load(json_file)\n",
    "\n",
    "    results_labeled = dict_ids_results(claim_json)\n",
    "    setting_name = setting.split('-')[0]\n",
    "    print(setting_name, len(count))\n",
    "\n",
    "    with open(f'{OUT_PATH}/doc_retrieval/bm25/{foldername}/{foldername}_dev_dict_bm25_{setting}.json', 'w') as json_file:\n",
    "        json.dump(results_labeled, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FAISS\n",
    "\n",
    "python3 -m src.retrieval.faiss.run_faiss_search --dataset_name=hover --setting=enwiki-2017-cite-full --hover_stage=sent_retrieval --precompute_embed --use_gpu  \n",
    "python3 -m src.retrieval.faiss.run_faiss_search --dataset_name=hover --setting=enwiki-2017-claim-full --hover_stage=sent_retrieval --precompute_embed --use_gpu  \n",
    "python3 -m src.retrieval.faiss.run_faiss_search --dataset_name=hover --setting=enwiki-2017-fusion-full --hover_stage=sent_retrieval --precompute_embed --use_gpu  \n",
    "\n",
    "python3 -m src.retrieval.faiss.run_faiss_search --dataset_name=wice --setting=enwiki-2023-cite-full --hover_stage=sent_retrieval --precompute_embed --use_gpu  \n",
    "python3 -m src.retrieval.faiss.run_faiss_search --dataset_name=wice --setting=enwiki-2023-claim-full --hover_stage=sent_retrieval --precompute_embed --use_gpu  \n",
    "python3 -m src.retrieval.faiss.run_faiss_search --dataset_name=wice --setting=enwiki-2023-fusion-full --hover_stage=sent_retrieval --precompute_embed --use_gpu  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original 0\n",
      "cite 0\n",
      "claim 0\n",
      "fusion 0\n"
     ]
    }
   ],
   "source": [
    "setting_files = [\"original-full-select\", \"cite-full\", \"claim-full\", \"fusion-full\"]\n",
    "for setting in setting_files:\n",
    "    DOC_PATH = os.path.join(BASE_PATH, \"hover_files\", foldername, \"faiss\", setting, \"sent_retrieval\", \"hover_dev_sent_retrieval.json\")\n",
    "    with open(DOC_PATH,\"r\") as json_file:\n",
    "        claim_json = json.load(json_file)\n",
    "    results_labeled = dict_ids_results(claim_json, id_key='id')\n",
    "    setting_name = setting.split('-')[0]\n",
    "    print(setting_name, len(count))\n",
    "    with open(f'{OUT_PATH}/doc_retrieval/faiss/{foldername}/{foldername}_dev_dict_faiss_{setting_name}.json', 'w') as json_file:\n",
    "        json.dump(results_labeled, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JPQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python -m src.retrieval.JPQ.run_inference --dataset_name=hover --setting=enwiki-2017-cite-full --subvectors_num 96 --sent_select --use_gpu  \n",
    "python -m src.retrieval.JPQ.run_inference --dataset_name=hover --setting=enwiki-2017-claim-full --subvectors_num 96 --sent_select --use_gpu  \n",
    "python -m src.retrieval.JPQ.run_inference --dataset_name=hover --setting=enwiki-2017-fusion-full --subvectors_num 96 --sent_select --use_gpu  \n",
    "\n",
    "python -m src.retrieval.JPQ.run_inference --dataset_name=wice --setting=enwiki-2023-cite-full --subvectors_num 96 --sent_select --use_gpu  \n",
    "python -m src.retrieval.JPQ.run_inference --dataset_name=wice --setting=enwiki-2023-claim-full --subvectors_num 96 --sent_select --use_gpu  \n",
    "python -m src.retrieval.JPQ.run_inference --dataset_name=wice --setting=enwiki-2023-fusion-full --subvectors_num 96 --sent_select --use_gpu  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original 0\n",
      "cite 0\n",
      "claim 0\n",
      "fusion 0\n"
     ]
    }
   ],
   "source": [
    "setting_files = [\"original-full-compress-select\", \"cite-full-compress\", \"claim-full-compress\", \"fusion-full-compress\"]\n",
    "for setting in setting_files:\n",
    "    DOC_PATH = os.path.join(BASE_PATH, \"hover_files\", foldername, \"faiss\", setting, \"sent_retrieval\", \"hover_dev_sent_retrieval.json\")\n",
    "    with open(DOC_PATH,\"r\") as json_file:\n",
    "        claim_json = json.load(json_file)\n",
    "    results_labeled = dict_ids_results(claim_json, id_key='id')\n",
    "    setting_name = setting.split('-')[0]\n",
    "    print(setting_name, len(count))\n",
    "    with open(f'{OUT_PATH}/doc_retrieval/jpq/{foldername}/{foldername}_dev_dict_jpq_{setting_name}.json', 'w') as json_file:\n",
    "        json.dump(results_labeled, json_file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grounding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
